{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iters = 2\n",
    "env_num = 2\n",
    "spec_num = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**** Learning Policy for Spec #3 in Env #2 ****\n",
      "\n",
      "**** Abstract Graph ****\n",
      "0 -> 1\n",
      "1 -> 2\n",
      "2 -> 2\n",
      "\n",
      "Learning policy for edge 0 -> 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guru/dirl/venv/lib/python3.11/site-packages/gym/spaces/box.py:127: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Steps taken at iteration 0: 1260\n",
      "Time taken at iteration 0: 0.006488247712453207 mins\n",
      "Expected reward at iteration 0: -439.8662170376224\n",
      "\n",
      "Steps taken at iteration 1: 2520\n",
      "Time taken at iteration 1: 0.012099850177764892 mins\n",
      "Expected reward at iteration 1: -422.007487901614\n",
      "\n",
      "Learning policy for edge 1 -> 2\n",
      "\n",
      "\n",
      "Steps taken at iteration 0: 1260\n",
      "Time taken at iteration 0: 0.00540237029393514 mins\n",
      "Expected reward at iteration 0: -55.07375798624198\n",
      "\n",
      "Steps taken at iteration 1: 2520\n",
      "Time taken at iteration 1: 0.010900564988454183 mins\n",
      "Expected reward at iteration 1: -54.456999149135555\n"
     ]
    }
   ],
   "source": [
    "from conformal.all_paths_conformal_pred import all_paths_conformal_pred\n",
    "from conformal.bucketed_conformal_pred import bucketed_conformal_pred\n",
    "from conformal.nonconformity_score_graph import DIRLCumRewardScoreGraph, DIRLTimeTakenScoreGraph\n",
    "from spectrl.hierarchy.construction import adj_list_from_task_graph, automaton_graph_from_spec\n",
    "from spectrl.hierarchy.reachability import HierarchicalPolicy, ConstrainedEnv\n",
    "from spectrl.main.spec_compiler import ev, seq, choose, alw\n",
    "from spectrl.util.io import parse_command_line_options, save_log_info, save_object\n",
    "from spectrl.util.rl import print_performance, get_rollout\n",
    "from spectrl.rl.ars import HyperParams\n",
    "\n",
    "from spectrl.examples.rooms_envs import (\n",
    "    GRID_PARAMS_LIST,\n",
    "    MAX_TIMESTEPS,\n",
    "    START_ROOM,\n",
    "    FINAL_ROOM,\n",
    ")\n",
    "from spectrl.envs.rooms import RoomsEnv\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "render = False\n",
    "folder = ''\n",
    "itno = -1\n",
    "\n",
    "log_info = []\n",
    "\n",
    "grid_params = GRID_PARAMS_LIST[env_num]\n",
    "\n",
    "hyperparams = HyperParams(30, num_iters, 30, 15, 0.05, 0.3, 0.15)\n",
    "\n",
    "print(\n",
    "    \"\\n**** Learning Policy for Spec #{} in Env #{} ****\".format(\n",
    "        spec_num, env_num\n",
    "    )\n",
    ")\n",
    "\n",
    "# Step 1: initialize system environment\n",
    "system = RoomsEnv(grid_params, START_ROOM[env_num], FINAL_ROOM[env_num])\n",
    "\n",
    "# Step 4: List of specs.\n",
    "if env_num == 2:\n",
    "    bottomright = (0, 2)\n",
    "    topleft = (2, 0)\n",
    "if env_num == 3 or env_num == 4:\n",
    "    bottomright = (0, 3)\n",
    "    topleft = (3, 0)\n",
    "\n",
    "# test specs\n",
    "spec0 = ev(grid_params.in_room(FINAL_ROOM[env_num]))\n",
    "spec1 = seq(\n",
    "    ev(grid_params.in_room(FINAL_ROOM[env_num])),\n",
    "    ev(grid_params.in_room(START_ROOM[env_num])),\n",
    ")\n",
    "spec2 = ev(grid_params.in_room(topleft))\n",
    "\n",
    "# Goto destination, return to initial\n",
    "spec3 = seq(\n",
    "    ev(grid_params.in_room(topleft)),\n",
    "    ev(grid_params.in_room(START_ROOM[env_num])),\n",
    ")\n",
    "# Choose between top-right and bottom-left blocks (Same difficulty - learns 3/4 edges)\n",
    "spec4 = choose(\n",
    "    ev(grid_params.in_room(bottomright)), ev(grid_params.in_room(topleft))\n",
    ")\n",
    "# Choose between top-right and bottom-left, then go to Final state (top-right).\n",
    "# Only one path is possible (learns 5/5 edges. Should have a bad edge)\n",
    "spec5 = seq(\n",
    "    choose(\n",
    "        ev(grid_params.in_room(bottomright)), ev(grid_params.in_room(topleft))\n",
    "    ),\n",
    "    ev(grid_params.in_room(FINAL_ROOM[env_num])),\n",
    ")\n",
    "# Add obsacle towards topleft\n",
    "spec6 = alw(grid_params.avoid_center((1, 0)), ev(grid_params.in_room(topleft)))\n",
    "# Either go to top-left or bottom-right. obstacle on the way to top-left.\n",
    "# Then, go to Final state. Only one route is possible\n",
    "spec7 = seq(\n",
    "    choose(\n",
    "        alw(grid_params.avoid_center((1, 0)), ev(grid_params.in_room(topleft))),\n",
    "        ev(grid_params.in_room(bottomright)),\n",
    "    ),\n",
    "    ev(grid_params.in_room(FINAL_ROOM[env_num])),\n",
    ")\n",
    "\n",
    "specs = [spec0, spec1, spec2, spec3, spec4, spec5, spec6, spec7]\n",
    "\n",
    "# Step 3: construct abstract reachability graph\n",
    "_, abstract_reach = automaton_graph_from_spec(specs[spec_num])\n",
    "print(\"\\n**** Abstract Graph ****\")\n",
    "abstract_reach.pretty_print()\n",
    "\n",
    "# Step 5: Learn policy\n",
    "path_policies = abstract_reach.learn_all_paths(\n",
    "    system,\n",
    "    hyperparams,\n",
    "    res_model=None,\n",
    "    max_steps=20,\n",
    "    render=render,\n",
    "    neg_inf=-100,\n",
    "    safety_penalty=-1,\n",
    "    num_samples=500,\n",
    ")\n",
    "\n",
    "adj_list = adj_list_from_task_graph(abstract_reach.abstract_graph)\n",
    "terminal_vertices = [i for i in range(len(adj_list)) if i in adj_list[i]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_taken_score_graph = DIRLTimeTakenScoreGraph(adj_list, path_policies)\n",
    "e = 0.1\n",
    "n_samples = 500\n",
    "total_buckets = 100\n",
    "vbs = bucketed_conformal_pred(time_taken_score_graph, e, total_buckets, n_samples)\n",
    "min_path, min_path_scores = all_paths_conformal_pred(time_taken_score_graph, e, n_samples)\n",
    "\n",
    "vb = vbs.buckets[(terminal_vertices[0], total_buckets)]\n",
    "print(\"Bucketed:\")\n",
    "print(vb.path)\n",
    "print(vb.path_buckets)\n",
    "print(vb.path_score_quantiles)\n",
    "print(max(vb.path_score_quantiles))\n",
    "\n",
    "print()\n",
    "print(\"All paths:\")\n",
    "print(min_path)\n",
    "print(min_path_scores)\n",
    "print(max(min_path_scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
